# Pos em Tecnologias Disruptivas IESB# Prof. Tatiana Saldanha Tavares 2018/2# Banco de dado MNIST. Faz a PCA, atribui rotulos com K-means e em seguida classifica # com Multi Layer Perceptron e Support Vector Machine# Instalar bibliotecasimport urllibimport _pickle as pickleimport osimport gzipimport numpy as npimport matplotlib.pyplot as pltimport matplotlib.cm as cmfrom time import process_timefrom sklearn.neural_network import MLPClassifierfrom sklearn.metrics import confusion_matrixfrom sklearn.metrics import classification_reportfrom sklearn.cluster import KMeansfrom sklearn import svmfrom sklearn.decomposition import PCAfrom sklearn.model_selection import train_test_split# Ler banco de dados - shape (N,784)def load_dataset():    url = 'http://deeplearning.net/data/mnist/mnist.pkl.gz'    filename = 'mnist.pkl.gz'    if not os.path.exists(filename):        print('Downloading MNIST dataset...')        urllib.request.urlretrieve(url, filename)    with gzip.open(filename, 'rb') as f:        data = pickle.load(f, encoding='latin1')            X, y = data[0]   #comparar y com y_pred_K    return X, yX,y = load_dataset()#X = X[0:1000] # subamostra dos dados # Plota imagem como vetor e como matrixX_vector = X.reshape((-1, 1, 1, 784))plt.imshow(X_vector[5][0], cmap=cm.binary)plt.show()X_matrix = X.reshape((-1, 1, 28, 28))plt.imshow(X_matrix[5][0], cmap=cm.binary)plt.show()# Calcular PCA de todo o conjunto de entradapca = PCA(n_components=300) #300 numero de eixos que eu queroX_projected = pca.fit_transform(X)print('Shape dados brutos: ' + str(X.shape))print('Shape dados PCA: ' + str(X_projected.shape))# Verificando o numero de componentesplt.plot(np.cumsum(pca.explained_variance_ratio_))plt.xlabel('numero de componentes')plt.ylabel('variancia cumulativa')plt.show()#Este banco de dados "nao eh rotulado", preciso verificar os clusters e rotular.# Set a KMeans clusteringkmeans = KMeans(n_clusters=10)# Compute cluster centers and predict cluster indicesy_pred_k = kmeans.fit_predict(X_projected)# plot em 2D com 2 componentesplt.scatter(X_projected[:, 0], X_projected[:, 1],            c=y_pred_k, edgecolor='none', alpha=0.5,            cmap=plt.cm.get_cmap('Accent', 10))plt.xlabel('component 1')plt.ylabel('component 2')plt.colorbar();plt.show()# Separa conjunto de train e val dos dados brutosX_train, X_val, y_train, y_val = train_test_split(X, y_pred_k, test_size=0.3,                                                     stratify=y_pred_k,                                                     random_state=42)# Separa conjunto de train e val da PCAprojected_train, projected_val, y_train, y_val = train_test_split(X_projected, y_pred_k, test_size=0.3,                                                     stratify=y_pred_k,                                                     random_state=42)# Definir arquitetura MLPmlp = MLPClassifier(hidden_layer_sizes=(200,), activation='relu', max_iter=1000, alpha=1e-4,                     solver='sgd', verbose=10, tol=1e-3, random_state=1, learning_rate_init=.01)# Aqui fazer um treinamento e uma validacao da MLP com dados brutosstart = process_time()mlp.fit(X_train, y_train)end = process_time()time_mlp = end - startprint('Tempo de treinamento_mlp_dados_brutos: ' + str(time_mlp))print('Erro no final do treinamento_mlp_dados_brutos: %f' % mlp.loss_)# Metricas da validacao MLP com dados brutospreds_val = mlp.predict(X_val)correct_outputs_val = y_valn_acertos_val = 0for u in range(0, len(correct_outputs_val)):   if preds_val[u] == correct_outputs_val[u]:       n_acertos_val += 1print('Number of acertos_val_mlp com dados brutos: ' + str((n_acertos_val*100)/len(correct_outputs_val)))print(confusion_matrix(y_val,preds_val))print(classification_report(y_val,preds_val))# Aqui fazer um treinamento e uma validacao da MLP com PCAstart = process_time()mlp.fit(projected_train, y_train)end = process_time()time_mlp = end - startprint('Tempo de treinamento_mlp_pca: ' + str(time_mlp))print("Erro no final do treinamento_mlp_pca: %f" % mlp.loss_)# Mericas da validacao MLP com PCApreds_val = mlp.predict(projected_val)correct_outputs_val = y_valn_acertos_val = 0for u in range(0, len(correct_outputs_val)):   if preds_val[u] == correct_outputs_val[u]:       n_acertos_val += 1print('Number of acertos_val_mlp com PCA: ' + str((n_acertos_val*100)/len(correct_outputs_val)))print(confusion_matrix(y_val,preds_val))print(classification_report(y_val,preds_val))## definir arquitetura da SVMsvm = svm.SVC(kernel='rbf',C =1, gamma='auto')# Aqui fazer um treinamento e uma validacao da SVM com dados brutosstart = process_time()svm.fit(X_train, y_train)end = process_time()time_svm = end - startprint('Tempo de treinamento_svm_dados_brutos: ' + str(time_svm))# Metricas da validacao SVM com dados brutospreds_val_svm= svm.predict(X_val)correct_outputs_val_svm = y_valn_acertos_val_svm = 0for u in range(0, len(correct_outputs_val_svm)):   if preds_val_svm[u] == correct_outputs_val_svm[u]:            n_acertos_val_svm += 1print('Number of acertos_val_svm_dados brutos: ' + str((n_acertos_val_svm*100)/len(correct_outputs_val_svm)))print(confusion_matrix(y_val,preds_val_svm))# Aqui fazer um treinamento e uma validacao da svm com PCAstart = process_time()svm.fit(projected_train, y_train)end = process_time()time_svm = end - startprint('Tempo de treinamento_svm_pca: ' + str(time_svm))# Metricas da validacao SVM com PCApreds_val_svm= svm.predict(projected_val)correct_outputs_val_svm = y_valn_acertos_val_svm = 0for u in range(0, len(correct_outputs_val_svm)):   if preds_val_svm[u] == correct_outputs_val_svm[u]:            n_acertos_val_svm += 1print('Number of acertos_val_svm PCA: ' + str((n_acertos_val_svm*100)/len(correct_outputs_val_svm)))print(confusion_matrix(y_val,preds_val_svm))# testar um unico exemplo exemplo_=projected_val[3,]exemplo = exemplo_.reshape((1, 300))pred_svm = svm.predict(exemplo)pred_mlp = mlp.predict(exemplo)